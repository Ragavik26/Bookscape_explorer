{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "# Install required libraries\n",
    "! pip install pandas streamlit matplotlib seaborn psycopg2 python-dotenv requests sqlalchemy\n",
    "\n",
    "# Import the libraries after installation\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 40 books so far...\n",
      "Fetched 80 books so far...\n",
      "Fetched 120 books so far...\n",
      "Fetched 160 books so far...\n",
      "Fetched 200 books so far...\n",
      "Fetched 240 books so far...\n",
      "Fetched 280 books so far...\n",
      "Fetched 320 books so far...\n",
      "Fetched 360 books so far...\n",
      "Fetched 400 books so far...\n",
      "Fetched 440 books so far...\n",
      "Fetched 480 books so far...\n",
      "Fetched 520 books so far...\n",
      "Fetched 560 books so far...\n",
      "Fetched 600 books so far...\n",
      "Fetched 640 books so far...\n",
      "Fetched 680 books so far...\n",
      "Fetched 720 books so far...\n",
      "Fetched 760 books so far...\n",
      "Fetched 800 books so far...\n",
      "Fetched 840 books so far...\n",
      "Fetched 880 books so far...\n",
      "Fetched 920 books so far...\n",
      "Fetched 960 books so far...\n",
      "Fetched 1000 books so far...\n",
      "Data saved to BooksData.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid  # For generating unique book IDs\n",
    "\n",
    "# Your Google Books API key\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "# Base URL for the Google Books API\n",
    "BASE_URL = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "\n",
    "def fetch_books(query, max_entries=1000):\n",
    "    \"\"\"\n",
    "    Fetch book data from Google Books API with pagination.\n",
    "\n",
    "    :param query: Search query for books.\n",
    "    :param max_entries: Maximum number of books to fetch.\n",
    "    :return: List of book dictionaries.\n",
    "    \"\"\"\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"API_KEY is not set. Please set it in your environment variables.\")\n",
    "\n",
    "    all_books = []\n",
    "    max_results = 40  # Maximum allowed by the API\n",
    "    start_index = 0\n",
    "\n",
    "    while len(all_books) < max_entries:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"startIndex\": start_index,\n",
    "            \"maxResults\": max_results,\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        items = data.get(\"items\", [])\n",
    "\n",
    "        if not items:\n",
    "            print(\"No more results available.\")\n",
    "            break\n",
    "\n",
    "        for item in items:\n",
    "            volume_info = item.get(\"volumeInfo\", {})\n",
    "            book = {\n",
    "                \"book_id\": str(uuid.uuid4()),  # Unique identifier for each book\n",
    "                \"search_key\": query,\n",
    "                \"book_title\": volume_info.get(\"title\", \"No Title\"),\n",
    "                \"book_subtitle\": volume_info.get(\"subtitle\", \"N/A\"),\n",
    "                \"book_authors\": \", \".join(volume_info.get(\"authors\", [\"Unknown Author\"])),\n",
    "                \"book_description\": volume_info.get(\"description\", \"No Description\"),\n",
    "                \"industryIdentifiers\": \", \".join([identifier.get(\"identifier\", \"N/A\") for identifier in volume_info.get(\"industryIdentifiers\", [])]),\n",
    "                \"text_readingModes\": volume_info.get(\"readingModes\", {}).get(\"text\", False),\n",
    "                \"image_readingModes\": volume_info.get(\"readingModes\", {}).get(\"image\", False),\n",
    "                \"pageCount\": volume_info.get(\"pageCount\", \"N/A\"),\n",
    "                \"categories\": \", \".join(volume_info.get(\"categories\", [\"N/A\"])),\n",
    "                \"language\": volume_info.get(\"language\", \"N/A\"),\n",
    "                \"imageLinks\": volume_info.get(\"imageLinks\", {}).get(\"thumbnail\", \"No Image\"),\n",
    "                \"ratingsCount\": volume_info.get(\"ratingsCount\", \"N/A\"),\n",
    "                \"averageRating\": volume_info.get(\"averageRating\", \"N/A\"),\n",
    "                \"country\": volume_info.get(\"country\", \"N/A\"),\n",
    "                \"saleability\": volume_info.get(\"saleability\", \"N/A\"),\n",
    "                \"isEbook\": volume_info.get(\"isEbook\", False),\n",
    "                \"amount_listPrice\": volume_info.get(\"listPrice\", {}).get(\"amount\", \"N/A\"),\n",
    "                \"currencyCode_listPrice\": volume_info.get(\"listPrice\", {}).get(\"currencyCode\", \"N/A\"),\n",
    "                \"amount_retailPrice\": volume_info.get(\"retailPrice\", {}).get(\"amount\", \"N/A\"),\n",
    "                \"currencyCode_retailPrice\": volume_info.get(\"retailPrice\", {}).get(\"currencyCode\", \"N/A\"),\n",
    "                \"buyLink\": volume_info.get(\"infoLink\", \"No Buy Link\"),\n",
    "                \"year\": volume_info.get(\"publishedDate\", \"N/A\").split(\"-\")[0],  # Extract year\n",
    "                \"publisher\": volume_info.get(\"publisher\", \"N/A\")\n",
    "            }\n",
    "            all_books.append(book)\n",
    "\n",
    "        # Increment the start index\n",
    "        start_index += max_results\n",
    "        print(f\"Fetched {len(all_books)} books so far...\")\n",
    "\n",
    "        # Stop if we've hit the max_entries limit\n",
    "        if len(all_books) >= max_entries:\n",
    "            break\n",
    "\n",
    "    return all_books[:max_entries]\n",
    "\n",
    "def save_books_to_csv(books, filename=\"BooksData.csv\"):\n",
    "    \"\"\"\n",
    "    Save book data to a CSV file.\n",
    "\n",
    "    :param books: List of book dictionaries.\n",
    "    :param filename: Name of the CSV file to save.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(books)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Main function to fetch and save books\n",
    "def main():\n",
    "    query = \"fiction\"  # Change to your preferred query\n",
    "    max_entries = 1000\n",
    "    try:\n",
    "        books = fetch_books(query, max_entries)\n",
    "        save_books_to_csv(books)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id                      object\n",
      "search_key                   object\n",
      "book_title                   object\n",
      "book_subtitle                object\n",
      "book_authors                 object\n",
      "book_description             object\n",
      "industryIdentifiers          object\n",
      "text_readingModes              bool\n",
      "image_readingModes             bool\n",
      "pageCount                     int64\n",
      "categories                   object\n",
      "language                     object\n",
      "imageLinks                   object\n",
      "ratingsCount                  int64\n",
      "averageRating               float64\n",
      "country                      object\n",
      "saleability                  object\n",
      "isEbook                        bool\n",
      "amount_listPrice            float64\n",
      "currencyCode_listPrice       object\n",
      "amount_retailPrice          float64\n",
      "currencyCode_retailPrice     object\n",
      "buyLink                      object\n",
      "year                         object\n",
      "publisher                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('BooksData.csv')\n",
    "#remove duplicates in the csv\n",
    "df.drop_duplicates()\n",
    "# Convert NaN into 0 to avoid error while converting columns into integer\n",
    "df['pageCount'] = df['pageCount'].fillna(0).astype(int)\n",
    "df['ratingsCount'] = df['ratingsCount'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Change data types of the columns\n",
    "df['book_id'] = df['book_id'].astype(str)\n",
    "df['search_key'] = df['search_key'].astype(str)\n",
    "df['book_title'] = df['book_title'].astype(str)\n",
    "df['book_subtitle'] = df['book_subtitle'].astype(str)\n",
    "df['book_authors'] = df['book_authors'].astype(str)\n",
    "df['book_description'] = df['book_description'].astype(str)\n",
    "df['industryIdentifiers'] = df['industryIdentifiers'].astype(str)\n",
    "df['text_readingModes'] = df['text_readingModes'].astype(bool)\n",
    "df['image_readingModes'] = df['image_readingModes'].astype(bool)\n",
    "df['pageCount'] = df['pageCount'].astype(int)\n",
    "df['categories'] = df['categories'].astype(str)\n",
    "df['language'] = df['language'].astype(str)\n",
    "df['imageLinks'] = df['imageLinks'].astype(str)\n",
    "df['ratingsCount'] = df['ratingsCount'].astype(int)\n",
    "df['averageRating'] = df['averageRating'].astype(float)\n",
    "df['country'] = df['country'].astype(str)\n",
    "df['saleability'] = df['saleability'].astype(str)\n",
    "df['isEbook'] = df['isEbook'].astype(bool)\n",
    "df['amount_listPrice'] = df['amount_listPrice'].astype(float)\n",
    "df['currencyCode_listPrice'] = df['currencyCode_listPrice'].astype(str)\n",
    "df['amount_retailPrice'] = df['amount_retailPrice'].astype(float)\n",
    "df['currencyCode_retailPrice'] = df['currencyCode_retailPrice'].astype(str)\n",
    "df['buyLink'] = df['buyLink'].astype(str)\n",
    "df['year'] = df['year'].astype(str)\n",
    "df['publisher'] = df['publisher'].astype(str)\n",
    "\n",
    "# Check the data types after conversion\n",
    "#print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted\n"
     ]
    }
   ],
   "source": [
    "# Load data into SQL\n",
    "# Load environment variables from the .env file txt \n",
    "# Database connection settings from environment variables\n",
    "load_dotenv()\n",
    "\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "user = os.getenv(\"DB_USER\")\n",
    "database = os.getenv(\"DB_NAME\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "try:\n",
    "    df.to_sql('books', engine, if_exists='append', index=False)\n",
    "    print(\"Successfully inserted\")\n",
    "except Exception as e:\n",
    "    print(f\"Error inserting data: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
